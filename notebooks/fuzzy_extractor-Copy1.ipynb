{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ../pyldpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# from python_fuzzy_extractor.fuzzy_extractor import FuzzyExtractor\n",
    "from python_fuzzy_extractor.fuzzy_extractor_LDPC import FuzzyExtractorLDPC as FuzzyExtractor\n",
    "from entropy import Entropy\n",
    "import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "# from fuzzy_extractor import FuzzyExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramters\n",
    "# enroll\n",
    "total_length = 16 # length of input of fuzzy extractor\n",
    "#The number of bits that can be flipped in the source value and \n",
    "# still produce the same key with probability (1 - rep_err).\n",
    "error_precision = 8\n",
    "top_score = 16# factor of 16\n",
    "blocks = int(top_score / total_length)\n",
    "using_max_entropy_or_random_perm = True\n",
    "perm_feat = False# use perm for each user?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.loadtxt('integerhashingcodes_embeddings_FVC2002_DB1_A_8x512.csv', dtype='int', delimiter=',')#512, binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FuzzyExtractor(total_length, error_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each user, generate mask from first 3 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.66it/s]\n"
     ]
    }
   ],
   "source": [
    "mess_len = embeddings.shape[1]\n",
    "masks=[]\n",
    "for i in tqdm.tqdm(range(100)):\n",
    "    samples = embeddings[i*5:i*5+3,:]\n",
    "    entropy_scores = []\n",
    "    for i in range(mess_len):\n",
    "        entropy_scores.append(Entropy(samples[:,i]))\n",
    "    entropy_scores_sort_idx = np.argsort(entropy_scores)\n",
    "    if using_max_entropy_or_random_perm:\n",
    "        remain_idx =np.array(entropy_scores_sort_idx, dtype=np.uint8)\n",
    "    else:\n",
    "        remain_idx =np.random.permutation(range(512))# if randomly generate index?\n",
    "    masks.append(remain_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what if we add some permutation? User-specific?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 48793.67it/s]\n"
     ]
    }
   ],
   "source": [
    "perms=[]\n",
    "for i in tqdm.tqdm(range(100)):\n",
    "    perms.append(np.random.permutation(range(top_score)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th samples as enrollment template, 5 as testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomExclude(n):\n",
    "    while True:\n",
    "        tmp = np.random.randint(0, 100, size=1)[0]\n",
    "        if tmp!=n:\n",
    "            break\n",
    "    return tmp\n",
    "\n",
    "flg=1# debug,one element \n",
    "\n",
    "\n",
    "def sub_enroll(i):\n",
    "    keys= []\n",
    "    helpers = []\n",
    "    samples = embeddings[i*5+3,:]\n",
    "    mask = masks[i][:top_score]\n",
    "    samples_masked = samples[mask]\n",
    "    # perm the hash codes\n",
    "    if perm_feat:\n",
    "        samples_masked = samples_masked[perms[i]]\n",
    "    for starti in range(blocks):\n",
    "        s = samples_masked[starti*total_length:(starti+1)*total_length]\n",
    "        # fuzzy extractor\n",
    "        key, helper = extractor.generate(s)\n",
    "        keys.append(key)\n",
    "        helpers.append(helper)\n",
    "    return keys,helpers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======  apply_async  ======\n",
      "Total time of Thread execution 113.4623 for the function \n"
     ]
    }
   ],
   "source": [
    "# enroll\n",
    "pool = Pool(processes = 12)\n",
    "start_time=time.perf_counter()\n",
    "results = []\n",
    "for i in range(100):\n",
    "    # 维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去\n",
    "    r1 = pool.apply_async(sub_enroll, args=(i, ))    \n",
    "    results.append(r1)\n",
    "print('======  apply_async  ======')\n",
    "pool.close()\n",
    "#调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束\n",
    "pool.join()\n",
    "\n",
    "\n",
    "keys= []\n",
    "helpers = []\n",
    "    \n",
    "for i in range(100):\n",
    "    ikeys,ihelpers = results[i].get(timeout=100)\n",
    "    keys.append(ikeys)\n",
    "    helpers.append(ihelpers)\n",
    "\n",
    "end_time=time.perf_counter()\n",
    "    \n",
    "print(f\"Total time of Thread execution {round(end_time- start_time,4)} for the function \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('masks.npy',masks)\n",
    "np.savez('keys.npy',keys)\n",
    "np.savez('embeddings.npy',embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable(v,filename):\n",
    "    f=open(filename,'wb')\n",
    "    pickle.dump(v,f)\n",
    "    f.close()\n",
    "    return filename\n",
    "\n",
    "def load_variavle(filename):\n",
    "   f=open(filename,'rb')\n",
    "   r=pickle.load(f)\n",
    "   f.close()\n",
    "   return r\n",
    "\n",
    "# filename = save_variable(helpers,'helpers.txt')\n",
    "# results = load_variavle('helpers.txt')\n",
    "#################################\n",
    "def sub_repro_imposter(i):\n",
    "    j = randomExclude(i)# imposter, random one\n",
    "    samples = embeddings[j*5+4,:]## using imposter biometric data\n",
    "    mask = masks[j][:top_score]\n",
    "    samples_masked = samples[mask]\n",
    "    key = keys[i]\n",
    "    helper = helpers[i]\n",
    "    # perm the hash codes\n",
    "    if perm_feat:\n",
    "        samples_masked = samples_masked[perms[i]]\n",
    "    positive_num=0\n",
    "    for starti in range(blocks):\n",
    "        p = samples_masked[starti*total_length:(starti+1)*total_length]\n",
    "        # fuzzy extractor reproduce\n",
    "        r_key = extractor.reproduce(p, helper[starti])  # r_key will probably still equal key!\n",
    "        if r_key and r_key==key[starti]:\n",
    "            positive_num = positive_num+1\n",
    "    return positive_num\n",
    "\n",
    "def sub_repro_imposter_disclosure_mask(i):\n",
    "    j = randomExclude(i)# imposter, random one\n",
    "    samples = embeddings[j*5+4,:]## using imposter biometric data\n",
    "    mask = masks[i][:top_score]\n",
    "    samples_masked = samples[mask]\n",
    "    key = keys[i]\n",
    "    helper = helpers[i]\n",
    "    # perm the hash codes\n",
    "    if perm_feat:\n",
    "        samples_masked = samples_masked[perms[j]]\n",
    "    positive_num=0\n",
    "    for starti in range(blocks):\n",
    "        p = samples_masked[starti*total_length:(starti+1)*total_length]\n",
    "        # fuzzy extractor reproduce\n",
    "        r_key = extractor.reproduce(p, helper[starti])  # r_key will probably still equal key!\n",
    "        if r_key and r_key==key[starti]:\n",
    "            positive_num = positive_num+1\n",
    "    return positive_num\n",
    "\n",
    "\n",
    "def sub_repro_genuine(i):\n",
    "    samples = embeddings[i*5+4,:]\n",
    "    mask = masks[i][:top_score]\n",
    "    samples_masked = samples[mask]\n",
    "    key = keys[i]\n",
    "    helper = helpers[i]\n",
    "\n",
    "    # perm the hash codes\n",
    "#     samples_masked = samples_masked[perms[i]]\n",
    "    if perm_feat:\n",
    "        samples_masked = samples_masked[perms[i]]\n",
    "    positive_num=0\n",
    "    for starti in range(blocks):        \n",
    "        p = samples_masked[starti*total_length:(starti+1)*total_length]\n",
    "        # fuzzy extractor reproduce\n",
    "        r_key = extractor.reproduce(p, helper[starti])  # r_key will probably still equal key!\n",
    "#         print('***********************************************')\n",
    "#         print('++++',r_key,key[starti],'******',starti)\n",
    "        if r_key and r_key==key[starti]:\n",
    "            positive_num = positive_num+1\n",
    "#         if r_key == None:\n",
    "#             continue\n",
    "#         elif abs(np.subtract(r_key, key[starti])).sum() == 0:#r_key==key[starti]\n",
    "#             positive_num = positive_num+1\n",
    "# #     print('process',i,positive_num)\n",
    "    return positive_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======  apply_async  ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time of Thread execution 121.5433 for the function \n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "#lets try 7th with mated\n",
    "positive_nums=[]\n",
    "\n",
    "pool = Pool(processes = 12)\n",
    "start_time=time.perf_counter()\n",
    "results = []\n",
    "for i in range(100):\n",
    "    # 维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去\n",
    "    r1 = pool.apply_async(sub_repro_genuine, args=(i, ))    \n",
    "    results.append(r1)\n",
    "print('======  apply_async  ======')\n",
    "pool.close()\n",
    "#调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束\n",
    "pool.join()\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    positive_nums.append(results[i].get(timeout=100))\n",
    "\n",
    "end_time=time.perf_counter()\n",
    "    \n",
    "print(f\"Total time of Thread execution {round(end_time- start_time,4)} for the function \")\n",
    "# print(positive_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "print(sum(np.array(positive_nums)>0)/len(positive_nums))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imposter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imposter knows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======  apply_async  ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time of Thread execution 113.8734 for the function \n"
     ]
    }
   ],
   "source": [
    "false_positive_nums = []\n",
    "pool = Pool(processes = 10)\n",
    "start_time=time.perf_counter()\n",
    "results = []\n",
    "for i in range(100):\n",
    "    # 维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去\n",
    "    r1 = pool.apply_async(sub_repro_imposter, args=(i, ))    \n",
    "    results.append(r1)\n",
    "print('======  apply_async  ======')\n",
    "pool.close()\n",
    "#调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束\n",
    "pool.join()\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    false_positive_nums.append(results[i].get(timeout=100))\n",
    "\n",
    "end_time=time.perf_counter()\n",
    "    \n",
    "print(f\"Total time of Thread execution {round(end_time- start_time,4)} for the function \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======  apply_async  ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n",
      "/home/charles/miniconda3/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time of Thread execution 117.813 for the function \n"
     ]
    }
   ],
   "source": [
    "false_positive_nums_same_mask = []\n",
    "pool = Pool(processes = 12)\n",
    "start_time=time.perf_counter()\n",
    "results = []\n",
    "for i in range(100):\n",
    "    # 维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去\n",
    "    r1 = pool.apply_async(sub_repro_imposter_disclosure_mask, args=(i, ))    \n",
    "    results.append(r1)\n",
    "print('======  apply_async  ======')\n",
    "pool.close()\n",
    "#调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束\n",
    "pool.join()\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    false_positive_nums_same_mask.append(results[i].get(timeout=100))\n",
    "\n",
    "end_time=time.perf_counter()\n",
    "    \n",
    "print(f\"Total time of Thread execution {round(end_time- start_time,4)} for the function \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "blocks 1\n",
      "threshold1: 1\n",
      "threshold2: 1\n",
      "tpr,fpr 0.73 0.0\n",
      "tpr,fpr_samemask 0.73 0.0\n"
     ]
    }
   ],
   "source": [
    "print(positive_nums)\n",
    "# print(false_positive_nums)\n",
    "print(false_positive_nums_same_mask)\n",
    "print(false_positive_nums)\n",
    "print('blocks',blocks)\n",
    "# print(false_positive_nums2)\n",
    "threshold1 = max(false_positive_nums)+1\n",
    "threshold2 = max(false_positive_nums_same_mask)+1\n",
    "# threshold = 1\n",
    "print('threshold1:',threshold1)\n",
    "print('threshold2:',threshold2)\n",
    "positive_nums = np.array(positive_nums)\n",
    "# false_positive_nums = np.array(false_positive_nums)\n",
    "false_positive_nums = np.array(false_positive_nums)\n",
    "false_positive_nums_same_mask = np.array(false_positive_nums_same_mask)\n",
    "\n",
    "## \n",
    "tpr = sum(positive_nums>=threshold1)/len(positive_nums)\n",
    "fpr = sum(false_positive_nums>=threshold1)/len(false_positive_nums)\n",
    "\n",
    "print('tpr,fpr',tpr,fpr)\n",
    "\n",
    "## \n",
    "tpr = sum(positive_nums>=threshold2)/len(positive_nums)\n",
    "fpr_same_mask = sum(false_positive_nums_same_mask>=threshold2)/len(false_positive_nums_same_mask)\n",
    "\n",
    "print('tpr,fpr_samemask',tpr,fpr_same_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16,6)) #创建幕布\n",
    "ax = fig.add_subplot(121) #截取幕布的一部分，121是简写，表示1行2列中的第1个图\n",
    "ns,edgeBin,patches = plt.hist(positive_nums,bins=30,rwidth=1)\n",
    "ns,edgeBin,patches = plt.hist(false_positive_nums,bins=30,rwidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16,6)) #创建幕布\n",
    "ax = fig.add_subplot(121) #截取幕布的一部分，121是简写，表示1行2列中的第1个图\n",
    "ns,edgeBin,patchesshape = plt.hist(positive_nums,bins=30,rwidth=1)\n",
    "ns,edgeBin,patches = plt.hist(false_positive_nums_same_mask,bins=30,rwidth=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result 0FAR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
